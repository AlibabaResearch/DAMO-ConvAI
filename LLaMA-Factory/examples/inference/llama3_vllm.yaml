model_name_or_path: saves/llama3-8b/sotopia/reason-model  # change this to the path of the model you want to use
template: llama3
infer_backend: vllm
vllm_enforce_eager: true
max_new_tokens: 4096
vllm_maxlen: 4096
flash_attn: fa2