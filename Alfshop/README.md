# Evaluation on WebShop and ALFWorld

We build our WebShop and ALFWorld implementation on top of [EPO] (https://github.com/Yifan-Song793/ETO/tree/main).


## Structure

There are three main folders in this directory: `envs`, `eval_agent`, `fastchat`

`envs`: the interaction environment of WebShop. We transform the original [WebShop](https://github.com/princeton-nlp/WebShop) repo into a package.

`eval_agent`: the evaluation framework of agent tasks, which is inspired by [MINT](https://github.com/xingyaoww/mint-bench).

`fastchat`: training scripts for EPO, which is a modified version of [FastChat](https://github.com/lm-sys/FastChat).


## Setup

```bash
bash setup.sh
```

The setup script performs the following actions:

- Install Python dependencies for agent training, deployment, evaluation, and the environments for WebShop, ALFWorld
- Download data and search engine indices for WebShop
- Download game files for ALFWorld


## Evaluation with a strategic reasoning model

First, launch the controller of FastChat
```bash
python -m fastchat.serve.controller
```

Then, launch the model worker of FastChat
```bash
python -m fastchat.serve.model_worker --model-path <YOUR_MODEL_PATH> --port 21002 --worker-address http://localhost:21002
```

Finally, evaluate the agent
```bash
python -m eval_agent.main --thought_agent_config fastchat --thought_model_name <REASON_MODEL_NAME> --action_agent_config openai --action_model_name <ACTION_MODEL_NAME> --exp_config <TASK_NAME> --split test --verbose
```


## ⚙️ How to Add a New Task

1. Implement your task loader in `eval_agent/tasks`. You should implement the `load_tasks` method which returns a task generator.
2. Implement the corresponding environment in `eval_agent/envs`. The environment should parse the action generated by the LLM agent, execute the action, and return the observation. The tool/API calling should also be implemented in the environment.
3. Write the instruction prompt and ICL examples in `eval_agent/prompt`. The default setting is 1-shot evaluation.
4. Write a new task config in `eval_agent/configs/task`. The config defines which task class and environment class to load, and the settings of the environment (e.g., max action steps).