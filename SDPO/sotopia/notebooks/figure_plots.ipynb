{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "from sotopia.database import EpisodeLog, AnnotationForEpisode\n",
    "from pydantic import ValidationError\n",
    "from sotopia.generation_utils.generate import LLM_Name\n",
    "from typing import get_args\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from rich.console import Console\n",
    "from sotopia.envs.evaluators import EvaluationBySocialDimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figures in the arXiv paper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 1\n",
    "\n",
    "Correlation between human scores and model scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOCIAL_DIMENSIONS: list[str] = list(EvaluationBySocialDimensions.__fields__.keys())\n",
    "social_dim_offest = {\n",
    "    \"relationship\": 0,\n",
    "    \"knowledge\": 0,\n",
    "    \"secret\": 0,\n",
    "    \"financial_and_material_benefits\": 0,\n",
    "    \"social_rules\": 0,\n",
    "    \"goal\": 0,\n",
    "    \"believability\": 0,\n",
    "}\n",
    "\n",
    "data_points: list[tuple[float, float]] = []\n",
    "annotation_pks = AnnotationForEpisode.all_pks()\n",
    "episode2human_annotations: dict[str, list[npt.NDArray[np.float32]]] = dict()\n",
    "for annotation_pk in annotation_pks:\n",
    "    annotation = AnnotationForEpisode.get(annotation_pk)\n",
    "    human_rewards = annotation.rewards\n",
    "    human_rewards_list: list[tuple[float, float]] = []\n",
    "    for social_dim in SOCIAL_DIMENSIONS:\n",
    "        human_rewards_list.append(\n",
    "            (\n",
    "                float(human_rewards[0][1][social_dim] + social_dim_offest[social_dim]),\n",
    "                float(human_rewards[1][1][social_dim] + social_dim_offest[social_dim]),\n",
    "            )\n",
    "        )\n",
    "    human_rewards_np = np.array(human_rewards_list)\n",
    "    if annotation.episode not in episode2human_annotations:\n",
    "        episode2human_annotations[annotation.episode] = [human_rewards_np]\n",
    "    else:\n",
    "        episode2human_annotations[annotation.episode].append(human_rewards_np)\n",
    "for episode_pk in episode2human_annotations:\n",
    "    all_human_annotations_for_episode = episode2human_annotations[episode_pk]\n",
    "    average_human_annotations_for_episode = np.mean(\n",
    "        all_human_annotations_for_episode, axis=0\n",
    "    )\n",
    "    model_rewards = EpisodeLog.get(episode_pk).rewards\n",
    "    if len(model_rewards) and not isinstance(model_rewards[0], float):\n",
    "        model_rewards_list: list[tuple[float, float]] = []\n",
    "        for social_dim in SOCIAL_DIMENSIONS:\n",
    "            model_rewards_list.append(\n",
    "                (\n",
    "                    float(\n",
    "                        model_rewards[0][1][social_dim] + social_dim_offest[social_dim]\n",
    "                    ),\n",
    "                    float(\n",
    "                        model_rewards[1][1][social_dim] + social_dim_offest[social_dim]\n",
    "                    ),\n",
    "                )\n",
    "            )\n",
    "        model_rewards_np = np.array(model_rewards_list)\n",
    "\n",
    "        for i in range(len(SOCIAL_DIMENSIONS)):\n",
    "            data_points.append(\n",
    "                (average_human_annotations_for_episode[i][0], model_rewards_np[i][0])\n",
    "            )\n",
    "            data_points.append(\n",
    "                (average_human_annotations_for_episode[i][1], model_rewards_np[i][1])\n",
    "            )\n",
    "\n",
    "data_points_np = np.array(data_points)\n",
    "## make a scatter plot with datapoints with a regression line\n",
    "### regression line with numpy\n",
    "reg = np.polyfit(data_points_np[:, 0], data_points_np[:, 1], 1)\n",
    "### scatter plot\n",
    "fig, ax = plt.subplots(figsize=(5, 5))\n",
    "data_points_unique, data_points_count = np.unique(\n",
    "    data_points_np, axis=0, return_counts=True\n",
    ")\n",
    "colors = np.abs(data_points_unique[:, 0] - data_points_unique[:, 1])\n",
    "ax.scatter(\n",
    "    data_points_unique[:, 0],\n",
    "    data_points_unique[:, 1],\n",
    "    np.sqrt(data_points_count) * 10,\n",
    "    alpha=0.5,\n",
    "    c=-colors,\n",
    "    cmap=\"coolwarm\",\n",
    ")\n",
    "ax.plot(data_points_np[:, 0], reg[0] * data_points_np[:, 0] + reg[1], color=\"#F86A6E\")\n",
    "ax.set_xlabel(\"human reward\")\n",
    "ax.set_ylabel(\"model reward\")\n",
    "ax.set_title(\"human vs model reward\")\n",
    "# ax.grid(True)\n",
    "plt.savefig(\"human_vs_model_reward.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 3\n",
    "\n",
    "Model performance with respect to social dimensions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first retrieve all episodes from the database with tag format: \"<model*1>*<model_2>\\_v0.0.1\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _is_valid_episode_log_pk(pk: str) -> bool:\n",
    "    try:\n",
    "        episode = EpisodeLog.get(pk=pk)\n",
    "    except ValidationError:\n",
    "        return False\n",
    "    try:\n",
    "        tag = episode.tag\n",
    "        model_1, model_2, version = tag.split(\"_\", maxsplit=2)\n",
    "        if (\n",
    "            model_1 in get_args(LLM_Name)\n",
    "            and model_2 in get_args(LLM_Name)\n",
    "            and version == \"v0.0.1_clean\"\n",
    "        ):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except (ValueError, AttributeError):\n",
    "        # ValueError: tag has less than 3 parts\n",
    "        # AttributeError: tag is None\n",
    "        return False\n",
    "\n",
    "\n",
    "episodes: list[EpisodeLog] = [\n",
    "    EpisodeLog.get(pk=pk)\n",
    "    for pk in filter(_is_valid_episode_log_pk, EpisodeLog.all_pks())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(episodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then for each model pair, calculate the average reward over all episodes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pair2performance: dict[tuple[LLM_Name, LLM_Name], npt.NDArray[np.float32]] = (\n",
    "    dict()\n",
    ")\n",
    "\n",
    "\n",
    "def _episode_rewards_to_np_array(\n",
    "    episode_rewards: list[tuple[float, dict[str, float]]],\n",
    ") -> npt.NDArray[np.float32]:\n",
    "    return np.array([list(i[1].values()) for i in episode_rewards])\n",
    "\n",
    "\n",
    "for episode in episodes:\n",
    "    _, model_1, model_2 = episode.models\n",
    "    try:\n",
    "        assert all(isinstance(i, tuple) for i in episode.rewards), episode.rewards\n",
    "        episode_rewards = _episode_rewards_to_np_array(episode.rewards)\n",
    "        if model_pair2performance.get((model_1, model_2)) is None:\n",
    "            model_pair2performance[(model_1, model_2)] = np.expand_dims(\n",
    "                episode_rewards, axis=0\n",
    "            )\n",
    "        else:\n",
    "            model_pair2performance[(model_1, model_2)] = np.vstack(\n",
    "                (\n",
    "                    model_pair2performance[(model_1, model_2)],\n",
    "                    np.expand_dims(episode_rewards, axis=0),\n",
    "                )\n",
    "            )\n",
    "    except AssertionError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregation over episodes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model_pair in model_pair2performance:\n",
    "    assert isinstance(model_pair2performance[model_pair], np.ndarray)\n",
    "    model_pair2performance[model_pair] = np.mean(\n",
    "        model_pair2performance[model_pair], axis=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print results for tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "console = Console()\n",
    "\n",
    "MODELS: list[LLM_Name] = [\n",
    "    \"gpt-4\",\n",
    "    \"gpt-3.5-turbo\",\n",
    "    \"togethercomputer/llama-2-70b-chat\",\n",
    "    \"togethercomputer/mpt-30b-chat\",\n",
    "]\n",
    "\n",
    "SOCIAL_DIMENSIONS: list[str] = list(EvaluationBySocialDimensions.__fields__.keys()) + [\n",
    "    \"overall\"\n",
    "]\n",
    "\n",
    "for i in range(8):\n",
    "    scores: dict[tuple[LLM_Name, LLM_Name], float] = defaultdict(float)\n",
    "    for model_pair in model_pair2performance:\n",
    "        scores[model_pair] = (\n",
    "            model_pair2performance[model_pair][0][i]\n",
    "            + model_pair2performance[model_pair[::-1]][1][i]\n",
    "        ) / 2\n",
    "    # table = Table(title=f\"SOCIAL_DIMENSION: {SOCIAL_DIMENSIONS[i]}\")\n",
    "    print(f\"SOCIAL_DIMENSION: {SOCIAL_DIMENSIONS[i]}\")\n",
    "    print(\"\\t\", end=\"\")\n",
    "    for model in MODELS:\n",
    "        print(f\"{model}\\t\", end=\"\")\n",
    "    print()\n",
    "    for model_1 in MODELS:\n",
    "        print(f\"{model_1}\\t\", end=\"\")\n",
    "        for model_2 in MODELS:\n",
    "            print(f\"{scores[(model_1, model_2)]:.2f}\\t\", end=\"\")\n",
    "        print()\n",
    "    # table.add_column(\"Model\")\n",
    "    # for model in MODELS:\n",
    "    #     table.add_column(model)\n",
    "    # for model_1 in MODELS:\n",
    "    #     table.add_row(model_1, *[f\"{scores[(model_1, model_2)]:.2f}\" for model_2 in MODELS])\n",
    "\n",
    "    # console.print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pair2performance.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "console = Console()\n",
    "\n",
    "MODELS: list[LLM_Name] = [\n",
    "    \"gpt-3.5-turbo\",\n",
    "    \"gpt-4\",\n",
    "    \"togethercomputer/llama-2-70b-chat\",\n",
    "    \"togethercomputer/mpt-30b-chat\",\n",
    "]\n",
    "\n",
    "SOCIAL_DIMENSIONS: list[str] = list(EvaluationBySocialDimensions.__fields__.keys()) + [\n",
    "    \"overall\"\n",
    "]\n",
    "table_dict_by_social_dimension: dict[str, dict[str, dict[str, float]]] = {}\n",
    "for i in range(8):\n",
    "    table_dict_by_social_dimension[SOCIAL_DIMENSIONS[i]] = {}\n",
    "    scores: dict[tuple[LLM_Name, LLM_Name], float] = defaultdict(float)\n",
    "    for model_pair in model_pair2performance:\n",
    "        scores[model_pair] = (\n",
    "            model_pair2performance[model_pair][0][i]\n",
    "            + model_pair2performance[model_pair[::-1]][1][i]\n",
    "        ) / 2\n",
    "    # table = Table(title=f\"SOCIAL_DIMENSION: {SOCIAL_DIMENSIONS[i]}\")\n",
    "    print(f\"SOCIAL_DIMENSION: {SOCIAL_DIMENSIONS[i]}\")\n",
    "    print(\"\\t\", end=\"\")\n",
    "    for model in MODELS:\n",
    "        print(f\"{model}\\t\", end=\"\")\n",
    "    for model_1 in MODELS:\n",
    "        table_dict_by_social_dimension[SOCIAL_DIMENSIONS[i]][model_1] = {}\n",
    "        for model_2 in MODELS:\n",
    "            table_dict_by_social_dimension[SOCIAL_DIMENSIONS[i]][model_1][model_2] = (\n",
    "                scores[(model_1, model_2)]\n",
    "            )\n",
    "dict_df_by_social_dimension = {\n",
    "    social_dimension: pd.DataFrame(table_dict_by_social_dimension[social_dimension])\n",
    "    for social_dimension in SOCIAL_DIMENSIONS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "dimension = dict_df_by_social_dimension[\"goal\"]\n",
    "dimension_copy = dimension.copy()\n",
    "dimension_copy = dimension_copy.rename(\n",
    "    columns={\"gpt-3.5-turbo\": \"gpt-3.5\", \"togethercomputer/llama-2-70b-chat\": \"llama-2\"}\n",
    ")\n",
    "dimension_copy = dimension_copy.rename(\n",
    "    index={\"gpt-3.5-turbo\": \"gpt-3.5\", \"togethercomputer/llama-2-70b-chat\": \"llama-2\"}\n",
    ")\n",
    "dimension_copy = dimension_copy.reindex([\"gpt-4\", \"gpt-3.5\", \"llama-2\"])\n",
    "dimension_copy = dimension_copy[[\"gpt-4\", \"gpt-3.5\", \"llama-2\"]]\n",
    "\n",
    "sns.heatmap(\n",
    "    dimension_copy, cmap=sns.color_palette(\"crest\", as_cmap=True), annot=True, fmt=\".2f\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "\n",
    "mpl.rcParams[\"figure.dpi\"] = 300\n",
    "# Assuming you have individual DataFrames for each dimension named dimension1, dimension2, etc.\n",
    "# For example: dimension1 = pd.DataFrame(...), dimension2 = pd.DataFrame(...), ...\n",
    "\n",
    "# List of dimension names\n",
    "dimension_names = [social_dimension for social_dimension in SOCIAL_DIMENSIONS]\n",
    "\n",
    "# Set up the plot grid\n",
    "grid_rows = 2  # Number of rows in the grid\n",
    "grid_cols = 4  # Number of columns in the grid\n",
    "fig, axes = plt.subplots(grid_rows, grid_cols, figsize=(15, 5))\n",
    "plt.subplots_adjust(wspace=0.5, hspace=0.5)  # Adjust spacing between subplots\n",
    "\n",
    "# Loop through each dimension and create a heatmap\n",
    "for idx, dimension_name in enumerate(dimension_names):\n",
    "    row = idx // grid_cols\n",
    "    col = idx % grid_cols\n",
    "    ax = axes[row, col]\n",
    "\n",
    "    dimension = dict_df_by_social_dimension[dimension_name]\n",
    "    dimension_copy = dimension.copy()\n",
    "    dimension_copy = dimension_copy.rename(\n",
    "        columns={\n",
    "            \"gpt-4\": \"GPT-4\",\n",
    "            \"gpt-3.5-turbo\": \"GPT-3.5\",\n",
    "            \"togethercomputer/llama-2-70b-chat\": \"Llama-2\",\n",
    "            \"togethercomputer/mpt-30b-chat\": \"MPT\",\n",
    "        }\n",
    "    )\n",
    "    dimension_copy = dimension_copy.rename(\n",
    "        index={\n",
    "            \"gpt-4\": \"GPT-4\",\n",
    "            \"gpt-3.5-turbo\": \"GPT-3.5\",\n",
    "            \"togethercomputer/llama-2-70b-chat\": \"Llama-2\",\n",
    "            \"togethercomputer/mpt-30b-chat\": \"MPT\",\n",
    "        }\n",
    "    )\n",
    "    dimension_copy = dimension_copy.reindex([\"GPT-4\", \"GPT-3.5\", \"Llama-2\", \"MPT\"])\n",
    "    dimension_copy = dimension_copy[[\"GPT-4\", \"GPT-3.5\", \"Llama-2\", \"MPT\"]]\n",
    "\n",
    "    sns.heatmap(dimension_copy, cmap=\"crest\", annot=True, fmt=\".2f\", ax=ax)\n",
    "    ax.set_title(f\"{dimension_name}\")\n",
    "\n",
    "# Adjust layout and show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"heatmap.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sotopia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
